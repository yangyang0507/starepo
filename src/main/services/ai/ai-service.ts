/**
 * AI æœåŠ¡
 * ä½¿ç”¨ ProviderFactoryã€MiddlewareChain å’Œ ModelCache
 */

import {
  ChatMessage,
  AISettings,
  AIResponse,
  AIError,
  AIErrorCode,
  ChatContext,
  RepositoryReference,
  StreamChunk,
  ToolCallInfo,
} from '@shared/types';
import type { AIProviderId, ProviderAccountConfig } from '@shared/types/ai-provider';
import { logger } from '@main/utils/logger';
import { generateText, streamText, stepCountIs } from 'ai';
import { initializeTools, tools } from './tools';
import { LanceDBSearchService } from '@main/services/search/lancedb-search-service';
import { globalProviderRegistry } from './registry-init';
import { ProviderFactory } from './providers/factory/provider-factory';
import { ModelResolver } from './core/models/model-resolver';
import { MiddlewareChain } from './core/middleware/middleware-chain';
import { LoggingMiddleware, RetryMiddleware, RateLimitMiddleware } from './core/middleware/built-in';
import { ModelCacheService } from './storage/model-cache-service';
import { ProviderAccountService } from './storage/provider-account-service';

export class AIService {
  private settings: AISettings | null = null;
  private conversationHistory: Map<string, ChatMessage[]> = new Map();
  private searchService: LanceDBSearchService;
  private toolsInitialized = false;

  // æ–°æ¶æ„ç»„ä»¶
  private providerFactory: ProviderFactory;
  private modelCache: ModelCacheService;
  private middlewareChain: MiddlewareChain;
  private providerAccountService: ProviderAccountService;

  constructor() {
    this.searchService = new LanceDBSearchService();
    this.providerAccountService = ProviderAccountService.getInstance();

    // åˆå§‹åŒ–æ¨¡å‹ç¼“å­˜
    this.modelCache = new ModelCacheService({
      ttl: 5 * 60 * 1000, // 5 åˆ†é’Ÿ
      maxSize: 10,
      cleanupIntervalMs: 60000,
    });

    // åˆå§‹åŒ–ä¸­é—´ä»¶é“¾
    this.middlewareChain = new MiddlewareChain()
      .use(new RateLimitMiddleware(60, 60000)) // 60 è¯·æ±‚/åˆ†é’Ÿ
      .use(new RetryMiddleware(3, 1000)) // æœ€å¤šé‡è¯• 3 æ¬¡
      .use(new LoggingMiddleware());

    // åˆå§‹åŒ– Provider å·¥å‚
    this.providerFactory = new ProviderFactory({
      registry: globalProviderRegistry,
      modelResolver: new ModelResolver({ strictMode: false }),
      middlewareChain: this.middlewareChain,
      accountProvider: async (providerId: AIProviderId) => {
        return await this.providerAccountService.getAccount(providerId);
      },
    });
  }

  /**
   * åˆå§‹åŒ– AI æœåŠ¡
   */
  async initialize(settings: AISettings): Promise<void> {
    try {
      if (!settings.enabled) {
        throw new AIError(AIErrorCode.NOT_CONFIGURED, 'AI service not configured');
      }

      const account = this.toProviderAccountConfig(settings);
      const provider = globalProviderRegistry.getProvider(account.providerId);

      if (!provider) {
        throw new AIError(AIErrorCode.NOT_CONFIGURED, `Unknown provider: ${account.providerId}`);
      }

      if (provider.validation.apiKeyRequired && !account.apiKey) {
        throw new AIError(AIErrorCode.NOT_CONFIGURED, 'AI service not configured');
      }

      if (provider.validation.baseUrlRequired && !account.baseUrl) {
        throw new AIError(AIErrorCode.NOT_CONFIGURED, 'AI service not configured');
      }

      this.settings = settings;

      // åˆå§‹åŒ–å·¥å…·ç³»ç»Ÿ
      if (!this.toolsInitialized) {
        await initializeTools(this.searchService);
        this.toolsInitialized = true;
      }

      logger.debug('AI service initialized with provider:', settings.provider);
    } catch (error) {
      logger.error('Failed to initialize AI service:', error);
      throw error;
    }
  }

  /**
   * èŠå¤©æ–¹æ³•
   */
  async chat(
    message: string,
    conversationId: string = 'default',
    userId?: string
  ): Promise<AIResponse> {
    if (!this.settings) {
      throw new AIError(AIErrorCode.NOT_CONFIGURED, 'AI service not initialized');
    }

    try {
      // æ„å»ºä¸Šä¸‹æ–‡
      const context: ChatContext = {
        conversationHistory: this.getConversationHistory(conversationId),
        userId,
      };

      // è°ƒç”¨ LLMï¼ˆå¯èƒ½åŒ…å«å·¥å…·è°ƒç”¨ï¼‰
      const response = await this.callLLMWithTools(message, context);

      // ä¿å­˜å¯¹è¯å†å²
      this.addMessageToHistory(conversationId, {
        id: `msg_${Date.now()}`,
        role: 'user',
        content: message,
        timestamp: Date.now(),
      });

      this.addMessageToHistory(conversationId, {
        id: `msg_${Date.now() + 1}`,
        role: 'assistant',
        content: response.content,
        timestamp: Date.now(),
      });

      return response;
    } catch (error) {
      logger.error('Chat error:', error);
      throw this.handleError(error);
    }
  }

  /**
   * æµå¼èŠå¤©æ–¹æ³•
   */
  async streamChat(
    message: string,
    conversationId: string = 'default',
    onChunk: (chunk: StreamChunk) => void,
    signal?: AbortSignal,
    userId?: string
  ): Promise<void> {
    if (!this.settings) {
      throw new AIError(AIErrorCode.NOT_CONFIGURED, 'AI service not initialized');
    }

    try {
      // ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
      this.addMessageToHistory(conversationId, {
        id: `msg_${Date.now()}`,
        role: 'user',
        content: message,
        timestamp: Date.now(),
      });

      // æ„å»ºä¸Šä¸‹æ–‡
      const context: ChatContext = {
        conversationHistory: this.getConversationHistory(conversationId),
        userId,
      };

      const model = await this.getModel();
      const systemPrompt = this.buildSystemPrompt();
      const messages = this.buildMessages(message, context);

      // ä½¿ç”¨ streamText è¿›è¡Œæµå¼è°ƒç”¨
      const result = streamText({
        model,
        system: systemPrompt,
        messages: messages.map((msg) => ({
          role: msg.role,
          content: msg.content,
        })),
        tools,
        stopWhen: stepCountIs(5), // ğŸ”§ å…è®¸æœ€å¤š 5 æ­¥ï¼ˆè°ƒç”¨å·¥å…· -> ç”Ÿæˆå›å¤ -> å¯èƒ½å†æ¬¡è°ƒç”¨å·¥å…·ï¼‰
        temperature: this.settings!.temperature || 0.7,
        topP: this.settings!.topP || 1.0,
        abortSignal: signal,
      });

      let fullText = '';
      const allReferences: RepositoryReference[] = [];
      const activeToolCalls = new Map<string, ToolCallInfo>();
      let hasTextDelta = false; // ğŸ”§ è·Ÿè¸ªæ˜¯å¦æ”¶åˆ°è¿‡ text-delta

      // å¤„ç†æµå¼äº‹ä»¶
      for await (const chunk of result.fullStream) {
        // æ£€æŸ¥æ˜¯å¦è¢«ä¸­æ–­
        if (signal?.aborted) {
          logger.debug('Stream aborted by signal');
          break;
        }

        switch (chunk.type) {
          case 'text-delta':
            hasTextDelta = true; // æ ‡è®°æ”¶åˆ°è¿‡ text-delta
            fullText += chunk.text; // AI SDK 5 ä½¿ç”¨ text å±æ€§
            onChunk({
              type: 'text',
              content: chunk.text,
            });
            break;

          case 'tool-call':
            {
              const toolCallInfo: ToolCallInfo = {
                id: chunk.toolCallId,
                name: chunk.toolName,
                status: 'calling',
                arguments: chunk.input as Record<string, unknown>, // AI SDK 5 ä½¿ç”¨ input
                startedAt: Date.now(),
              };
              activeToolCalls.set(chunk.toolCallId, toolCallInfo);
              onChunk({
                type: 'tool',
                content: '',
                toolCall: toolCallInfo,
              });
            }
            break;

          case 'tool-result':
            {
              const toolCallInfo = activeToolCalls.get(chunk.toolCallId);
              if (toolCallInfo) {
                toolCallInfo.status = 'result';
                toolCallInfo.result = chunk.output; // AI SDK 5 ä½¿ç”¨ output
                toolCallInfo.endedAt = Date.now();

                // æ”¶é›†ä»“åº“å¼•ç”¨
                if (chunk.output && typeof chunk.output === 'object') {
                  const resultObj = chunk.output as { repositories?: RepositoryReference[] };
                  if (resultObj.repositories && Array.isArray(resultObj.repositories)) {
                    allReferences.push(...resultObj.repositories);
                  }
                }

                onChunk({
                  type: 'tool',
                  content: '',
                  toolCall: toolCallInfo,
                });
              }
            }
            break;

          case 'error':
            {
              // AI SDK 5 çš„ error å¯èƒ½æ˜¯ errorText æˆ– error
              const errorMessage = (chunk as any).errorText ||
                                   ((chunk as any).error instanceof Error ? (chunk as any).error.message : String((chunk as any).error)) ||
                                   'Unknown error';
              logger.error('Stream error:', errorMessage);
              onChunk({
                type: 'error',
                content: '',
                error: errorMessage,
              });
            }
            break;

          case 'finish':
            {
              // ğŸ”§ å…œåº•é€»è¾‘ï¼šå¦‚æœæ²¡æœ‰æ”¶åˆ°ä»»ä½• text-deltaï¼Œè®°å½•è­¦å‘Š
              if (!hasTextDelta && fullText === '') {
                logger.warn('No text-delta received during stream, response may be empty');
              }

              // å‘é€ç»“æŸäº‹ä»¶ï¼ˆä¸å†å°è¯•ä» chunk è·å– textï¼Œå› ä¸º AI SDK 5 çš„ finish æ²¡æœ‰è¯¥å±æ€§ï¼‰
              onChunk({
                type: 'end',
                content: fullText,
                metadata: {
                  references: allReferences.length > 0 ? allReferences : undefined,
                },
              });
            }
            break;
        }
      }

      // ä¿å­˜åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
      this.addMessageToHistory(conversationId, {
        id: `msg_${Date.now()}`,
        role: 'assistant',
        content: fullText,
        timestamp: Date.now(),
        references: allReferences.length > 0 ? allReferences : undefined,
      });
    } catch (error) {
      logger.error('Stream chat error:', error);
      const aiError = this.handleError(error);
      onChunk({
        type: 'error',
        content: '',
        error: aiError.message,
      });
      throw aiError;
    }
  }

  /**
   * è·å–æ¨¡å‹å®ä¾‹ï¼ˆå¸¦ç¼“å­˜ï¼‰
   */
  private async getModel() {
    if (!this.settings) {
      throw new AIError(AIErrorCode.NOT_CONFIGURED, 'Settings not available');
    }

    const account = this.toProviderAccountConfig(this.settings);
    const modelId = this.settings.model?.trim() || undefined;
    const modelSpec = modelId ? `${account.providerId}|${modelId}` : account.providerId;

    // ç”Ÿæˆç¼“å­˜é”®
    const cacheKey = ModelCacheService.generateKey(
      account.providerId,
      modelId || 'default',
      account.baseUrl
    );

    // å°è¯•ä»ç¼“å­˜è·å–
    let model = this.modelCache.get(cacheKey);
    if (model) {
      logger.debug('Using cached model:', cacheKey);
      return model;
    }

    // åˆ›å»ºæ–°æ¨¡å‹å®ä¾‹
    logger.debug('Creating new model:', modelSpec);
    model = await this.providerFactory.createLanguageModelWithAccount(
      account.providerId,
      account,
      modelId
    );

    // ç¼“å­˜æ¨¡å‹å®ä¾‹
    this.modelCache.set(cacheKey, model);

    return model;
  }

  /**
   * è°ƒç”¨ LLMï¼ˆå¸¦å·¥å…·æ”¯æŒï¼‰
   */
  private async callLLMWithTools(message: string, context: ChatContext): Promise<AIResponse> {
    const model = await this.getModel();
    const systemPrompt = this.buildSystemPrompt();
    const messages = this.buildMessages(message, context);

    const result = await generateText({
      model,
      system: systemPrompt,
      messages: messages.map((msg) => ({
        role: msg.role,
        content: msg.content,
      })),
      tools,
      stopWhen: stepCountIs(5), // ğŸ”§ å…è®¸æœ€å¤š 5 æ­¥å·¥å…·è°ƒç”¨
      temperature: this.settings!.temperature || 0.7,
      topP: this.settings!.topP || 1.0,
    });

    // æ”¶é›†å·¥å…·è°ƒç”¨ç»“æœä¸­çš„ä»“åº“å¼•ç”¨
    const allReferences: RepositoryReference[] = [];
    if (result.steps && result.steps.length > 0) {
      for (const step of result.steps) {
        if (step.toolResults && step.toolResults.length > 0) {
          for (const toolResult of step.toolResults) {
            // AI SDK v5: toolResult ç›´æ¥åŒ…å«ç»“æœæ•°æ®
            if (toolResult && typeof toolResult === 'object') {
              const resultObj = toolResult as { repositories?: RepositoryReference[] };
              if (resultObj.repositories && Array.isArray(resultObj.repositories)) {
                allReferences.push(...resultObj.repositories);
              }
            }
          }
        }
      }
    }

    return {
      content: result.text,
      references: allReferences,
      usage: {
        promptTokens: result.usage.inputTokens ?? 0,
        completionTokens: result.usage.outputTokens ?? 0,
        totalTokens: (result.usage.inputTokens ?? 0) + (result.usage.outputTokens ?? 0),
      },
    };
  }

  /**
   * æ„å»ºç³»ç»Ÿæç¤ºè¯
   */
  private buildSystemPrompt(): string {
    return `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ GitHub ä»“åº“åŠ©æ‰‹ã€‚ä½ å¯ä»¥å¸®åŠ©ç”¨æˆ·æœç´¢ã€è¿‡æ»¤å’Œåˆ†æ GitHub ä»“åº“ã€‚

ä½ æœ‰ä»¥ä¸‹å·¥å…·å¯ç”¨ï¼š

1. **search_repositories** - æœç´¢ä»“åº“
   - ç”¨é€”ï¼šæ ¹æ®å…³é”®è¯æœç´¢ä»“åº“ï¼ˆåŒ¹é…åç§°ã€æè¿°ã€ä¸»é¢˜ï¼‰
   - å‚æ•°ï¼šqueryï¼ˆæœç´¢å…³é”®è¯ï¼‰ã€limitï¼ˆç»“æœæ•°é‡ï¼‰ã€sortByï¼ˆæ’åºå­—æ®µï¼‰ã€sortOrderï¼ˆæ’åºé¡ºåºï¼‰
   - ç¤ºä¾‹ï¼šç”¨æˆ·é—®"æŸ¥æ‰¾ React ç›¸å…³é¡¹ç›®"æ—¶ä½¿ç”¨

2. **filter_repositories** - ç­›é€‰ä»“åº“
   - ç”¨é€”ï¼šæŒ‰æ¡ä»¶ç­›é€‰ä»“åº“ï¼ˆè¯­è¨€ã€æ˜Ÿæ•°ã€æ—¶é—´èŒƒå›´ï¼‰
   - å‚æ•°ï¼šlanguageï¼ˆç¼–ç¨‹è¯­è¨€ï¼‰ã€minStars/maxStarsï¼ˆæ˜Ÿæ•°èŒƒå›´ï¼‰ã€dateRangeï¼ˆæ—¶é—´èŒƒå›´ï¼‰ã€limitã€sortByã€sortOrder
   - ç¤ºä¾‹ï¼šç”¨æˆ·é—®"æœ€è¿‘ä¸€å‘¨çš„ Python é¡¹ç›®"æˆ–"1000+ stars çš„ Go é¡¹ç›®"æ—¶ä½¿ç”¨
   - **é‡è¦**ï¼šdateRange.field æ”¯æŒä¸‰ç§æ—¶é—´å­—æ®µï¼š
     * **starred**ï¼šå…³æ³¨æ—¶é—´ï¼ˆç”¨æˆ· star è¯¥ä»“åº“çš„æ—¶é—´ï¼‰- ç”¨äº"æˆ‘å…³æ³¨äº†"ã€"æˆ‘ star äº†"ç­‰æŸ¥è¯¢
     * **created**ï¼šä»“åº“åˆ›å»ºæ—¶é—´
     * **updated**ï¼šä»“åº“æ›´æ–°æ—¶é—´
   - æ—¶é—´èŒƒå›´ç¤ºä¾‹ï¼š
     * æœ€è¿‘ä¸€å‘¨å…³æ³¨çš„é¡¹ç›®ï¼šdateRange.field="starred", dateRange.start="2026-01-03"ï¼ˆä»Šå¤©æ˜¯ 2026-01-10ï¼‰
     * æœ€è¿‘ä¸€å‘¨æ›´æ–°çš„é¡¹ç›®ï¼šdateRange.field="updated", dateRange.start="2026-01-03"
     * æœ€è¿‘ä¸€ä¸ªæœˆåˆ›å»ºçš„é¡¹ç›®ï¼šdateRange.field="created", dateRange.start="2025-12-10"

3. **get_popular_repositories** - è·å–çƒ­é—¨ä»“åº“
   - ç”¨é€”ï¼šè·å–æœ€å—æ¬¢è¿çš„ä»“åº“
   - å‚æ•°ï¼šlimitï¼ˆç»“æœæ•°é‡ï¼‰ã€languageï¼ˆå¯é€‰ï¼ŒæŒ‰è¯­è¨€ç­›é€‰ï¼‰
   - ç¤ºä¾‹ï¼šç”¨æˆ·é—®"æœ€çƒ­é—¨çš„é¡¹ç›®"æˆ–"æœ€å—æ¬¢è¿çš„ JavaScript é¡¹ç›®"æ—¶ä½¿ç”¨

4. **get_repository_details** - è·å–ä»“åº“è¯¦æƒ…
   - ç”¨é€”ï¼šè·å–ç‰¹å®šä»“åº“çš„è¯¦ç»†ä¿¡æ¯
   - å‚æ•°ï¼šownerï¼ˆä»“åº“æ‰€æœ‰è€…ï¼‰ã€repoï¼ˆä»“åº“åç§°ï¼‰
   - ç¤ºä¾‹ï¼šç”¨æˆ·é—®"facebook/react çš„è¯¦ç»†ä¿¡æ¯"æ—¶ä½¿ç”¨

5. **get_repositories_by_topic** - æŒ‰ä¸»é¢˜è·å–ä»“åº“
   - ç”¨é€”ï¼šæŸ¥æ‰¾ç‰¹å®šä¸»é¢˜æ ‡ç­¾çš„ä»“åº“
   - å‚æ•°ï¼štopicï¼ˆä¸»é¢˜æ ‡ç­¾ï¼‰ã€limitï¼ˆç»“æœæ•°é‡ï¼‰
   - ç¤ºä¾‹ï¼šç”¨æˆ·é—®"machine-learning ä¸»é¢˜çš„é¡¹ç›®"æ—¶ä½¿ç”¨

é‡è¦æç¤ºï¼š
- **å½“ç”¨æˆ·è¯¢é—®"æˆ‘å…³æ³¨äº†"ã€"æˆ‘ star äº†"ã€"æˆ‘æœ€è¿‘å…³æ³¨"ç­‰é—®é¢˜æ—¶**ï¼Œå¿…é¡»ä½¿ç”¨ filter_repositories å·¥å…·ï¼Œå¹¶è®¾ç½® dateRange.field="starred"
- å½“ç”¨æˆ·è¯¢é—®"æœ€è¿‘ä¸€å‘¨"ã€"æœ€è¿‘ä¸€ä¸ªæœˆ"ç­‰æ—¶é—´ç›¸å…³é—®é¢˜æ—¶ï¼Œæ ¹æ®ä¸Šä¸‹æ–‡åˆ¤æ–­ï¼š
  * å¦‚æœæ˜¯"æˆ‘å…³æ³¨çš„"ã€"æˆ‘ star çš„" â†’ ä½¿ç”¨ dateRange.field="starred"
  * å¦‚æœæ˜¯"æ›´æ–°çš„"ã€"æ´»è·ƒçš„" â†’ ä½¿ç”¨ dateRange.field="updated"
  * å¦‚æœæ˜¯"åˆ›å»ºçš„"ã€"æ–°å»ºçš„" â†’ ä½¿ç”¨ dateRange.field="created"
- ä¼˜å…ˆä½¿ç”¨å·¥å…·è·å–æ•°æ®ï¼Œè€Œä¸æ˜¯ç›´æ¥å›ç­”"æ— æ³•è®¿é—®"
- æ ¹æ®ç”¨æˆ·é—®é¢˜é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ï¼Œå¯ä»¥ç»„åˆä½¿ç”¨å¤šä¸ªå·¥å…·

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œä¸»åŠ¨ä½¿ç”¨è¿™äº›å·¥å…·æ¥æä¾›å‡†ç¡®çš„ç­”æ¡ˆã€‚`;
  }

  /**
   * æ„å»ºæ¶ˆæ¯åˆ—è¡¨
   */
  private buildMessages(
    currentMessage: string,
    context: ChatContext
  ): Array<{ role: 'user' | 'assistant'; content: string }> {
    const messages: Array<{ role: 'user' | 'assistant'; content: string }> = [];

    // æ·»åŠ å¯¹è¯å†å²ï¼ˆæœ€è¿‘ 10 æ¡ï¼‰
    const history = context.conversationHistory || [];
    const recentHistory = history.slice(-10);

    for (const msg of recentHistory) {
      messages.push({
        role: msg.role as 'user' | 'assistant',
        content: msg.content,
      });
    }

    // æ·»åŠ å½“å‰æ¶ˆæ¯
    messages.push({
      role: 'user',
      content: currentMessage,
    });

    return messages;
  }

  /**
   * è½¬æ¢ä¸º ProviderAccountConfig
   */
  private toProviderAccountConfig(settings: AISettings): ProviderAccountConfig {
    return {
      providerId: settings.provider as AIProviderId,
      apiKey: settings.apiKey,
      baseUrl: settings.baseURL,
      defaultModel: settings.model,
      timeout: 30000,
      retries: 3,
      strictTLS: true,
      enabled: settings.enabled,
    };
  }

  /**
   * è·å–å¯¹è¯å†å²
   */
  private getConversationHistory(conversationId: string): ChatMessage[] {
    return this.conversationHistory.get(conversationId) || [];
  }

  /**
   * æ·»åŠ æ¶ˆæ¯åˆ°å†å²
   */
  private addMessageToHistory(conversationId: string, message: ChatMessage): void {
    const history = this.conversationHistory.get(conversationId) || [];
    history.push(message);

    // é™åˆ¶å†å²é•¿åº¦
    const MAX_HISTORY = 100;
    if (history.length > MAX_HISTORY) {
      history.splice(0, history.length - MAX_HISTORY);
    }

    this.conversationHistory.set(conversationId, history);
  }

  /**
   * é”™è¯¯å¤„ç†
   */
  private handleError(error: unknown): AIError {
    if (error instanceof AIError) {
      return error;
    }

    if (error instanceof Error) {
      const message = error.message.toLowerCase();
      if (message.includes('401') || message.includes('unauthorized')) {
        return new AIError(AIErrorCode.INVALID_API_KEY, 'Invalid API Key', 401);
      } else if (message.includes('429') || message.includes('rate limit')) {
        return new AIError(AIErrorCode.RATE_LIMITED, 'Rate limited', 429);
      }
      return new AIError(AIErrorCode.LLM_ERROR, `LLM error: ${error.message}`);
    }

    return new AIError(AIErrorCode.LLM_ERROR, `Unknown error: ${String(error)}`);
  }

  /**
   * ç”Ÿæˆå¯¹è¯æ ‡é¢˜
   * ä½¿ç”¨ AI æ ¹æ®å¯¹è¯å†…å®¹ç”Ÿæˆç®€æ´çš„æ ‡é¢˜
   */
  async generateTitle(input: {
    conversationId: string;
    firstUserMessage: string;
    firstAssistantMessage?: string;
    tempTitle: string;
    modelId?: string;
  }): Promise<{ title: string }> {
    try {
      // æ„å»º Prompt
      const prompt = `è¯·ä¸ºä»¥ä¸‹å¯¹è¯ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ ‡é¢˜ï¼ˆä¸è¶…è¿‡20ä¸ªå­—ï¼‰ï¼Œåªè¾“å‡ºJSONæ ¼å¼ï¼š{"title":"..."}

ç”¨æˆ·ï¼š${input.firstUserMessage}
${input.firstAssistantMessage ? `åŠ©æ‰‹ï¼š${input.firstAssistantMessage}` : ''}

è¦æ±‚ï¼š
1. æ ‡é¢˜è¦ç®€æ´æ˜äº†ï¼Œèƒ½æ¦‚æ‹¬å¯¹è¯ä¸»é¢˜
2. ä¸è¶…è¿‡20ä¸ªå­—
3. åªè¾“å‡ºJSONæ ¼å¼ï¼Œä¸è¦å…¶ä»–å†…å®¹`;

      // è·å–å½“å‰å¯ç”¨çš„ Provider è´¦æˆ·
      const enabledAccount = await this.providerAccountService.getEnabledAccount();
      if (!enabledAccount) {
        // å¦‚æœæ²¡æœ‰å¯ç”¨çš„è´¦æˆ·ï¼Œè¿”å›ä¸´æ—¶æ ‡é¢˜
        logger.warn('[AIService] No enabled account for title generation, using temp title');
        return { title: input.tempTitle };
      }

      // ä½¿ç”¨ä¾¿å®œçš„æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
      const model = await this.getModel();

      // è°ƒç”¨ AI ç”Ÿæˆæ ‡é¢˜
      const result = await generateText({
        model,
        prompt,
        temperature: 0.2, // ä½æ¸©åº¦ï¼Œå‡å°‘éšæœºæ€§
        maxTokens: 50, // é™åˆ¶ token æ•°é‡
      });

      // è§£æ JSON å“åº”
      const text = result.text.trim();

      // å°è¯•æå– JSON
      let jsonMatch = text.match(/\{[^}]*"title"[^}]*\}/);
      if (jsonMatch) {
        const parsed = JSON.parse(jsonMatch[0]);
        if (parsed.title && typeof parsed.title === 'string') {
          const title = parsed.title.trim();
          logger.info(`[AIService] Generated title for ${input.conversationId}: ${title}`);
          return { title };
        }
      }

      // å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•ç›´æ¥æå–å¼•å·å†…çš„å†…å®¹
      const quoteMatch = text.match(/"([^"]+)"/);
      if (quoteMatch && quoteMatch[1]) {
        const title = quoteMatch[1].trim();
        logger.info(`[AIService] Extracted title from quotes: ${title}`);
        return { title };
      }

      // å¦‚æœéƒ½å¤±è´¥ï¼Œè¿”å›ä¸´æ—¶æ ‡é¢˜
      logger.warn('[AIService] Failed to parse title, using temp title');
      return { title: input.tempTitle };

    } catch (error) {
      logger.error('[AIService] Failed to generate title:', error);
      // å¤±è´¥æ—¶è¿”å›ä¸´æ—¶æ ‡é¢˜
      return { title: input.tempTitle };
    }
  }

  /**
   * æ¸…ç†èµ„æº
   */
  async cleanup(): Promise<void> {
    this.modelCache.stopCleanup();
    this.modelCache.clear();
    this.conversationHistory.clear();
    logger.debug('AI service cleaned up');
  }

  /**
   * è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯
   */
  get stats() {
    return {
      cacheStats: this.modelCache.stats,
      middlewareStats: this.middlewareChain.size,
      conversationCount: this.conversationHistory.size,
    };
  }
}
